{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2019db12-1b55-498b-92d7-f6376037e908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded MFG_1_To_8999_SF_CSV.csv with shape (487, 51)\n",
      "✅ Loaded MFG_9000_To_19000_SF_CSV.csv with shape (490, 51)\n",
      "✅ Loaded MFG_40k_To_140K_SF_CSV.csv with shape (496, 51)\n",
      "✅ Loaded MFG_140k_To_2Milli_SF_CSV.csv with shape (170, 51)\n",
      "✅ Loaded MFG_19000_To_40000_SF_CSV.csv with shape (491, 51)\n",
      "\n",
      "✅ Combined 5 files into a DataFrame with 2134 rows and 51 columns.\n"
     ]
    }
   ],
   "source": [
    "# Using glob to merge our costar export data to get around 499 Record Limit\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Get a list of all CSV files in the current directory\n",
    "csv_files = glob.glob('*.csv')\n",
    "\n",
    "# Loop and read each CSV and add it to a list of DataFrames\n",
    "dfs = []\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        dfs.append(df)\n",
    "        print(f\"✅ Loaded {file} with shape {df.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to read {file}: {e}\")\n",
    "\n",
    "# Combine all DataFrames into one\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Optional: Save the result to a new CSV file\n",
    "combined_df.to_csv('All_Costar_MFG_Exports_Combined.csv', index=False)\n",
    "\n",
    "print(f\"\\n✅ Combined {len(csv_files)} files into a DataFrame with {combined_df.shape[0]} rows and {combined_df.shape[1]} columns.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05af805-88f8-4b48-8144-ebf56604f71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(combined_df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f551be5-3981-4a53-9c7a-bd88e3c6efb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' from simple_salesforce import Salesforce\n",
    "# Replace these placeholders with your Salesforce credentials\n",
    "USERNAME = 'jgilmour@lee-associates.com'  # Your Salesforce username\n",
    "PASSWORD = 'Jazzy777.'  # Your Salesforce password\n",
    "SECURITY_TOKEN = 'K7J31vLvNcoImesGFm1iqXc84'\n",
    "\n",
    "# Replace these with your credentials\n",
    "sf = Salesforce(USERNAME,PASSWORD,SECURITY_TOKEN,domain='login')\n",
    "\n",
    "# Test query\n",
    "query = \"\"\"\n",
    "SELECT Sub_Market_Name__c, ascendix__Property__r.Name, Property_Record_Type__c, \n",
    "Property_Sub_Type__c, Total_Land_Area_SF__c, ascendix__ListingPrice__c,\n",
    "Listing_Price_PSF__c, ascendix__ListingBrokerContact__r.Name, \n",
    "ascendix__ListingBrokerCompany__r.Name, ascendix__SaleDate__c, ascendix__Property__Costar_ID__c,\n",
    "FROM ascendix__Property__c\n",
    "\"\"\"\n",
    "\n",
    "#Execute into DF\n",
    "results = sf.query(query)\n",
    "\n",
    "print(results)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923a9e62-6fda-41a7-82c6-d5f9339b87a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' # Get metadata for all accessible objects, checking our user permissions\n",
    "all_objects = sf.describe()['sobjects']\n",
    "\n",
    "# Filter for objects with \"Property\" in their name or label\n",
    "property_objects = [\n",
    "    (obj['name'], obj['label']) \n",
    "    for obj in all_objects \n",
    "    if 'property' in obj['name'].lower() or 'property' in obj['label'].lower()\n",
    "]\n",
    "\n",
    "# Display the results\n",
    "for api_name, label in property_objects:\n",
    "    print(f\"{label} → {api_name}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3fee555-b245-41a3-95be-46ac69f14cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading both exports with pandas and loading into csv so that we can merge on matching (PK) --> costar Id's\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load Ascendix data\n",
    "ascendix_df = pd.read_csv(r\"Ascendix_Where_Costar__ID_Not_Blank.csv\")\n",
    "\n",
    "# Load Costar data\n",
    "costar_df = pd.read_csv(r\"All_Costar_MFG_Exports_Combined.csv\")\n",
    "\n",
    "# Looking at df's\n",
    "ascendix_df.head()\n",
    "costar_df.head()\n",
    "\n",
    "\n",
    "# By default, Ascendix & Costar will normalize data differently ---> need to standardize\n",
    "costar_df[\"PropertyID\"] = costar_df[\"PropertyID\"].astype(str)\n",
    "ascendix_df[\"PropertyID\"] = ascendix_df[\"PropertyID\"].astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133542e5-9031-4734-a97e-d992e89279c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that our df has proper column headers\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    print(costar_df.head())  # or df.head(100) if you want more rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ef86c4-69a8-4cbe-824f-5b173c65dbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to Standardize column names on PK C_ID\n",
    "\n",
    "ascendix_df.rename(columns={\"Costar\": \"PropertyID\"}, inplace=True)\n",
    "print(ascendix_df)\n",
    "# Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1785204-7c27-4bde-85f5-fc5c41d7fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets on Costar ID\n",
    "# I want to isolate only the Costar Properties that are NOT found in Ascendix \n",
    "merged_df = costar_df.merge(ascendix_df, on=\"PropertyID\", how=\"left\", indicator=True)\n",
    "\n",
    "# Identify missing properties (PropertyID's that exist in Costar and not in Ascendix ---> 'left_only'\n",
    "missing_properties = merged_df[merged_df[\"_merge\"] == \"left_only\"]\n",
    "\n",
    "# Save missing properties to a NEW CSV so that they are all in one place for further investigation \n",
    "missing_properties.to_csv(\"missing_properties.csv\", index=False)\n",
    "\n",
    "# List all column names\n",
    "print(missing_properties.columns)\n",
    "# Print the number of rows in missing_properties\n",
    "print(f\"Number of rows: {len(missing_properties)}\")\n",
    "# Summary of the DataFrame\n",
    "missing_properties.info()\n",
    "# Print the shape of the DataFrame\n",
    "print(f\"Shape of missing_properties: {missing_properties.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3458424-30d1-46df-810a-311e0c1a760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move PK to front of DF to make more workable\n",
    "\n",
    "# Get the list of columns\n",
    "cols = list(missing_properties.columns)\n",
    "\n",
    "# Move 'PropertyID' to be after 'PropertyAddress'\n",
    "cols.remove(\"PropertyID\")  # Remove it from its current position\n",
    "index = cols.index(\"Property Address\") + 1  # Find position after 'PropertyAddress'\n",
    "cols.insert(index, \"PropertyID\")  # Insert it there\n",
    "\n",
    "# Reorder the DataFrame\n",
    "missing_properties = missing_properties[cols]\n",
    "\n",
    "# Double check change took effect\n",
    "\n",
    "print(missing_properties)\n",
    "missing_properties.to_csv(\"missing_properties_Final_V.csv\", index=False)\n",
    "'''missing_properties.to_csv(\"missing_properties.csv\", index=False)'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5610484-decf-49d4-b58b-305f27c2bcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = missing_properties[missing_properties.duplicated(subset=[\"PropertyID\"], keep=False)]\n",
    "print(f\"Shape of dupes: {duplicates.shape}\")\n",
    "print(duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec9d3ae8-8a78-4bfd-90d8-2e13bc4ae4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Read\n",
      "               Property Address  PropertyID Property Name_x Property Type  \\\n",
      "0                  5713 13th St    19686100      Building A          Flex   \n",
      "1                 201 6th St. N    12290276             NaN          Flex   \n",
      "2             2418 N Frazier St    12719672    Building 107          Flex   \n",
      "3               1904 Hialeah Dr     5785312             NaN          Flex   \n",
      "4                104 E Motel Dr    10298615             NaN          Flex   \n",
      "..                          ...         ...             ...           ...   \n",
      "533          1502 Fort Worth St    20590008             NaN    Industrial   \n",
      "534          1502 Fort Worth St    20590006      Building 1    Industrial   \n",
      "535  12221 N Houston Rosslyn Rd    12632772      Building C    Industrial   \n",
      "536              14888 Kirby Dr    20296859             NaN    Industrial   \n",
      "537              8450 Rayson Rd    20817727             NaN    Industrial   \n",
      "\n",
      "    Building Class Building Status    RBA  Total Available Space (SF)  \\\n",
      "0                B        Existing   6836                      6836.0   \n",
      "1                B        Existing   7000                      7000.0   \n",
      "2                C        Existing   6750                      3550.0   \n",
      "3                C        Existing   5638                      5638.0   \n",
      "4                C        Existing   3850                      3850.0   \n",
      "..             ...             ...    ...                         ...   \n",
      "533              C        Existing  19966                         NaN   \n",
      "534              C        Existing  23774                         NaN   \n",
      "535              C        Existing  38751                         NaN   \n",
      "536            NaN        Existing  35700                         NaN   \n",
      "537              B        Existing  27610                         NaN   \n",
      "\n",
      "          Secondary Type  Market Name  ... Land Area (AC)   Latitude  \\\n",
      "0    Light Manufacturing  Houston, TX  ...           2.25  29.799063   \n",
      "1    Light Manufacturing  Houston, TX  ...           0.38  29.386164   \n",
      "2    Light Manufacturing  Houston, TX  ...           9.53  30.343285   \n",
      "3    Light Manufacturing  Houston, TX  ...           1.35  29.572737   \n",
      "4    Light Manufacturing  Houston, TX  ...           0.61  29.427161   \n",
      "..                   ...          ...  ...            ...        ...   \n",
      "533        Manufacturing  Houston, TX  ...          25.55  30.049073   \n",
      "534        Manufacturing  Houston, TX  ...          25.55  30.048999   \n",
      "535        Manufacturing  Houston, TX  ...           2.78  29.908017   \n",
      "536        Manufacturing  Houston, TX  ...          16.73  29.588086   \n",
      "537        Manufacturing  Houston, TX  ...           1.64  29.825835   \n",
      "\n",
      "    Max Building Contiguous Space Office Space   Owner Contact Tax Year  \\\n",
      "0                          6836.0          NaN             NaN   2024.0   \n",
      "1                          7000.0          NaN             NaN   2024.0   \n",
      "2                          2450.0          NaN  Linda Cantrell   2023.0   \n",
      "3                          5638.0          NaN    Debbie Rogan   2024.0   \n",
      "4                          3850.0          NaN   Jerry Starkey   2024.0   \n",
      "..                            ...          ...             ...      ...   \n",
      "533                           NaN          NaN             NaN   2024.0   \n",
      "534                           NaN          NaN             NaN   2024.0   \n",
      "535                           NaN       9000.0             NaN   2024.0   \n",
      "536                           NaN          NaN             NaN   2023.0   \n",
      "537                           NaN          NaN   Lewis Talbert   2024.0   \n",
      "\n",
      "    Vacancy %  Longitude Property Name_y     _merge  \n",
      "0       100.0 -95.823358             NaN  left_only  \n",
      "1       100.0 -94.902887             NaN  left_only  \n",
      "2        52.6 -95.465395             NaN  left_only  \n",
      "3       100.0 -95.025462             NaN  left_only  \n",
      "4       100.0 -95.245885             NaN  left_only  \n",
      "..        ...        ...             ...        ...  \n",
      "533       NaN -94.818070             NaN  left_only  \n",
      "534       NaN -94.817025             NaN  left_only  \n",
      "535       NaN -95.497998             NaN  left_only  \n",
      "536       NaN -95.401741             NaN  left_only  \n",
      "537       NaN -95.498491             NaN  left_only  \n",
      "\n",
      "[538 rows x 53 columns]\n"
     ]
    }
   ],
   "source": [
    "# Hard coding ID's where crane > 1 as MFG into own column\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"MFG_missing_properties_in_Final_V.csv\")\n",
    "print(\"Completed Read\")\n",
    "print(missing_properties)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f55c0f73-a106-4b26-8fea-81bbe6b4ce42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Property Address                  object\n",
      "PropertyID                         int64\n",
      "Property Name_x                   object\n",
      "Property Type                     object\n",
      "Building Class                    object\n",
      "Building Status                   object\n",
      "RBA                                int64\n",
      "Total Available Space (SF)       float64\n",
      "Secondary Type                    object\n",
      "Market Name                       object\n",
      "Submarket Name                    object\n",
      "Leasing Company Name              object\n",
      "Leasing Company Contact           object\n",
      "Submarket Cluster                 object\n",
      "City                              object\n",
      "State                             object\n",
      "Zip                               object\n",
      "County Name                       object\n",
      "Sale Company Name                 object\n",
      "Sale Company Contact              object\n",
      "For Sale Price                   float64\n",
      "For Sale Status                   object\n",
      "Last Sale Date                    object\n",
      "Last Sale Price                   object\n",
      "Percent Leased                   float64\n",
      "Year Built                       float64\n",
      "Year Renovated                   float64\n",
      "Parking Ratio                    float64\n",
      "Tenancy                           object\n",
      "Floodplain Area                   object\n",
      "Ceiling Ht                        object\n",
      "Column Spacing                    object\n",
      "Number Of Cranes                  object\n",
      "Number Of Loading Docks          float64\n",
      "Drive Ins                         object\n",
      "Power                             object\n",
      "Rail Lines                        object\n",
      "Sewer                             object\n",
      "Building Park                     object\n",
      "Construction Material             object\n",
      "Direct Available Space           float64\n",
      "Direct Vacant Space                int64\n",
      "Flood Risk Area                   object\n",
      "Land Area (AC)                   float64\n",
      "Latitude                         float64\n",
      "Max Building Contiguous Space    float64\n",
      "Office Space                     float64\n",
      "Owner Contact                     object\n",
      "Tax Year                         float64\n",
      "Vacancy %                        float64\n",
      "Longitude                        float64\n",
      "Property Name_y                  float64\n",
      "_merge                            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Datatype check\n",
    "\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2fb58da-46bf-468e-8e41-57ff5080affa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing_properties\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNumber Of Cranes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2024.02-py310/lib/python3.10/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2024.02-py310/lib/python3.10/site-packages/pandas/core/arraylike.py:60\u001b[0m, in \u001b[0;36mOpsMixin.__ge__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__ge__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__ge__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mge\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2024.02-py310/lib/python3.10/site-packages/pandas/core/series.py:5803\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5800\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   5801\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 5803\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5805\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2024.02-py310/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:346\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 346\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-2024.02-py310/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:131\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    129\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32mops.pyx:107\u001b[0m, in \u001b[0;36mpandas._libs.ops.scalar_compare\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '>=' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "df['missing_properties'] = np.where(df['Number Of Cranes'] >= 1, 'Yes', 'No') \n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6701ad4-6189-476c-abd2-9cb0a86a0166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Property Address', 'PropertyID', 'Property Name_x', 'Property Type', 'Building Class', 'Building Status', 'RBA', 'Total Available Space (SF)', 'Secondary Type', 'Market Name', 'Submarket Name', 'Leasing Company Name', 'Leasing Company Contact', 'Submarket Cluster', 'City', 'State', 'Zip', 'County Name', 'Sale Company Name', 'Sale Company Contact', 'For Sale Price', 'For Sale Status', 'Last Sale Date', 'Last Sale Price', 'Percent Leased', 'Year Built', 'Year Renovated', 'Parking Ratio', 'Tenancy', 'Floodplain Area', 'Ceiling Ht', 'Column Spacing', 'Number Of Cranes', 'Number Of Loading Docks', 'Drive Ins', 'Power', 'Rail Lines', 'Sewer', 'Building Park', 'Construction Material', 'Direct Available Space', 'Direct Vacant Space', 'Flood Risk Area', 'Land Area (AC)', 'Latitude', 'Max Building Contiguous Space', 'Office Space', 'Owner Contact', 'Tax Year', 'Vacancy %', 'Longitude', 'Property Name_y', '_merge']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1afb0cd-ab3f-4405-b9ed-88c59704159c",
   "metadata": {},
   "outputs": [],
   "source": [
    " print(missing_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848cf56-b7e6-4e6d-8f0c-4c547377f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 1011 Costar ID Blank, 7166 Costar ID NOT Blank ---> Final Csv After Cleaning = 538 MFG Properties\n",
    "\n",
    "    538 \n",
    "\n",
    "IF crane > 1 we hardcode as mfg no matter what    ''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872c1223-4dd6-4be5-be3e-1a906fe943c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "''''\n",
    "import pandas as pd\n",
    "from simple_salesforce import Salesforce\n",
    "\n",
    "# Authenticate\n",
    "USERNAME = 'jgilmour@lee-associates.com'  # Your Salesforce username\n",
    "PASSWORD = 'Nalanala7777.'  # Your Salesforce password\n",
    "SECURITY_TOKEN = 'SQhuuEAv1e3jjUy0oS5JPUI8h'\n",
    "sf = Salesforce(username=USERNAME, password=PASSWORD, security_token=SECURITY_TOKEN)\n",
    "\n",
    "\n",
    "\n",
    "# First we need to load the missing_properties.csv into a Pandas DataFrame\n",
    "# missing_properties.csv MUST have headers that align with Salesforce field names\n",
    "# Batches?\n",
    "missing_properties_df = pd.read_csv(\"missing_properties.csv\")\n",
    "\n",
    "# Iterate through the DataFrame and add each property\n",
    "for index, row in missing_properties_df.iterrows():\n",
    "    try:\n",
    "        property_data = {\n",
    "            \"Record_Type__c\": row[\"Record Type\"],  # EXAMPLE FIELD MAPPINGS, NEED TO GET ALL Squared away before pushing fr fr\n",
    "            \"Property_Sub_Type__c\": row[\"Property Sub Type\"], # For every field that needs to be populated in Ascendix, find the Salesforce API field name and pair it with the matching header name from Cleaned CSV\n",
    "            \"Property_Name__c\": row[\"Property Name\"],\n",
    "            \"Location_Description__c\": row[\"Location Description\"],\n",
    "            \"Street__c\": row[\"Street\"],\n",
    "            \"City__c\": row[\"City\"],\n",
    "            \"State_Province__c\": row[\"State/Province\"],\n",
    "            \"Zip_Postal_Code__c\": row[\"Zip/Postal Code\"],\n",
    "            \"County__c\": row[\"County\"],\n",
    "            \"Geolocation_Coordinates__c\": row[\"Geolocation Coordinates\"],\n",
    "            \"Costar_ID__c\": row[\"Costar ID\"],\n",
    "            \"Tenancy__c\": row[\"Tenancy\"],\n",
    "            \"Building_Status__c\": row[\"Building Status\"],\n",
    "            \"Submarket__c\": row[\"Submarket\"],\n",
    "            \"Market__c\": row[\"Market\"],\n",
    "            \"Region__c\": row[\"Region\"],\n",
    "            \"Total_Building_Area_SF__c\": row[\"Total Building Area (SF)\"],\n",
    "            \"Office_Area_SF__c\": row[\"Office Area (SF)\"],\n",
    "            \"Total_Land_Area_Acres__c\": row[\"Total Land Area (Acres)\"],\n",
    "            \"Loading_Type__c\": row[\"Loading Type\"],\n",
    "            \"Docks__c\": row[\"Docks\"],\n",
    "            \"Drive_Ins__c\": row[\"Drive Ins\"],\n",
    "            \"Parking_Total__c\": row[\"Parking (Total)\"],\n",
    "            \"Listing_Broker_Company__c\": row[\"Listing Broker Company\"],\n",
    "            \"Listing_Broker_Contact__c\": row[\"Listing Broker Contact\"],\n",
    "        }\n",
    "            #Salesforce_API_names           #Header Names from CSV We cleaned from Costar on Right Side\n",
    "        # Add property to Ascendix\n",
    "        sf.Property__c.create(property_data)    #create method of the simple_salesforce library to add records programmatically.\n",
    "        print(f\"Successfully added property: {row['Property Name']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding property: {row['Property Name']} - {e}\")\n",
    "\n",
    "\n",
    "# Need to add some sort of logging logic to handle failed inserts and make troubleshooting more straightforward\n",
    "''''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
